{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import os\n",
    "import docx\n",
    "from docx import Document\n",
    "import nltk # Library nltk\n",
    "from nltk.tokenize import word_tokenize\t\t# Impor word_tokenize dari NLTK\n",
    "from nltk.corpus import stopwords\n",
    "import string # Library string\n",
    "import numpy as np\n",
    "import prettytable  \n",
    "from prettytable import PrettyTable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOKUMEN PERTAMA :\n",
      " Universitas. Islam, Negeri di Sumatera Utara\n",
      "\n",
      "\n",
      "DOKUMEN KEDUA :\n",
      " Universitas dalam, Sumatera. Utara\n"
     ]
    }
   ],
   "source": [
    "#read document\n",
    "raw_document1 = open(r\"C:\\Users\\Rambee\\Documents\\PROJECT\\python\\file\\dokumen 1.docx\",\"rb\")\n",
    "raw_document2 = open(r\"C:\\Users\\Rambee\\Documents\\PROJECT\\python\\file\\dokumen 2.docx\",\"rb\")\n",
    "\n",
    "read_doc1 = docx.Document(raw_document1)\n",
    "read_doc2 = docx.Document(raw_document2)\n",
    "\n",
    "def extrak_document(read_doc):\n",
    "    #read_doc2 = docx.Document(doc2)\n",
    "    document = \"\"\n",
    "    for para in read_doc.paragraphs:\n",
    "          document += para.text\n",
    "    return document\n",
    "\n",
    "document1 = extrak_document(read_doc1)\n",
    "document2 = extrak_document(read_doc2)\n",
    "print (\"DOKUMEN PERTAMA :\\n\",document1)\n",
    "print ('\\n')\n",
    "print (\"DOKUMEN KEDUA :\\n\",document2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSING DOKUMEN PERTAMA :\n",
      " universitasislamnegerisumaterautara\n",
      "\n",
      "\n",
      "PREPROCESSING DOKUMEN KEDUA :\n",
      " universitassumaterautara\n"
     ]
    }
   ],
   "source": [
    "# preprocessing    \n",
    "# lowercase\n",
    "lowercase1 = document1.lower()\n",
    "lowercase2 = document2.lower()\n",
    "\n",
    "#cleansing\n",
    "cleansing1 = lowercase1.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "cleansing2 = lowercase2.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "#tokenizing\n",
    "tokens1 = word_tokenize(cleansing1)\n",
    "tokens2 = word_tokenize(cleansing2)\n",
    "\n",
    "#filtering\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "filtering1 = [i for i in tokens1 if not i in stop_words]\n",
    "filtering2 = [i for i in tokens2 if not i in stop_words]\n",
    "\n",
    "result1 = (\"\".join(filtering1))\n",
    "result2 = (\"\".join(filtering2))\n",
    "print (\"PREPROCESSING DOKUMEN PERTAMA :\\n\",result1)\n",
    "print ('\\n')\n",
    "print (\"PREPROCESSING DOKUMEN KEDUA :\\n\",result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-GRAM DOKUMEN PERTAMA :\n",
      " ['uni', 'niv', 'ive', 'ver', 'ers', 'rsi', 'sit', 'ita', 'tas', 'asi', 'sis', 'isl', 'sla', 'lam', 'amn', 'mne', 'neg', 'ege', 'ger', 'eri', 'ris', 'isu', 'sum', 'uma', 'mat', 'ate', 'ter', 'era', 'rau', 'aut', 'uta', 'tar', 'ara']\n",
      "\n",
      "\n",
      "K-GRAM DOKUMEN PERTAMA :\n",
      " ['uni', 'niv', 'ive', 'ver', 'ers', 'rsi', 'sit', 'ita', 'tas', 'ass', 'ssu', 'sum', 'uma', 'mat', 'ate', 'ter', 'era', 'rau', 'aut', 'uta', 'tar', 'ara']\n"
     ]
    }
   ],
   "source": [
    "#inisialisasi nilai variabel\n",
    "k, b, w = 3, 2, 4\n",
    "\n",
    "def make_kgrams(s, t):\t#membuat kgram\n",
    "\tgrams = []\n",
    "\tstart, end = 0, t\n",
    "\twhile start < len(s) - t + 1:\n",
    "\t\tgrams.append(s[start:end])\n",
    "\t\tstart += 1\n",
    "\t\tend += 1\n",
    "\treturn grams\n",
    "\n",
    "k_grams1 = make_kgrams(result1, k)\n",
    "k_grams2 = make_kgrams(result2, k)\n",
    "print (\"K-GRAM DOKUMEN PERTAMA :\\n\",k_grams1)\n",
    "print ('\\n')\n",
    "print (\"K-GRAM DOKUMEN PERTAMA :\\n\",k_grams2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLLING HASH DOKUMEN PERTAMA :\n",
      " [793, 768, 757, 788, 747, 791, 786, 749, 773, 723, 785, 758, 773, 735, 716, 757, 745, 711, 728, 737, 781, 767, 803, 783, 746, 721, 780, 729, 767, 738, 797, 772, 713]\n",
      "\n",
      "\n",
      "ROLLING HASH DOKUMEN KEDUA :\n",
      " [793, 768, 757, 788, 747, 791, 786, 749, 773, 733, 807, 803, 783, 746, 721, 780, 729, 767, 738, 797, 772, 713]\n"
     ]
    }
   ],
   "source": [
    "def make_hash(grams):\t\t\t\n",
    "\thashpertama = []\n",
    "\trolling_hash = 0\n",
    "\tfor i in range(k):\n",
    "\t\trolling_hash = (ord(grams[0][i]) * (b ** (k-(i+1))))\n",
    "\t\thashpertama.append(rolling_hash)\n",
    "\treturn hashpertama\n",
    "\n",
    "hashpertama1 = (sum(make_hash(k_grams1)))\n",
    "hashpertama2 = (sum(make_hash(k_grams2)))\n",
    "\n",
    "def rolling_hash(hashpertama,k_grams):\n",
    "    list_rollinghash = [hashpertama]\n",
    "    for i in range(len(k_grams)-1):\n",
    "        hasher = (((list_rollinghash[i] - (ord(k_grams[i][0]) * (b ** (k-1)))) * b) + ord(k_grams[i+1][k-1]))\n",
    "        list_rollinghash.append(hasher)\n",
    "    return list_rollinghash\n",
    "\n",
    "final_hash1 = rolling_hash(hashpertama1,k_grams1)\n",
    "final_hash2 = rolling_hash(hashpertama2,k_grams2)\n",
    "print (\"ROLLING HASH DOKUMEN PERTAMA :\\n\",final_hash1)\n",
    "print ('\\n')\n",
    "print (\"ROLLING HASH DOKUMEN KEDUA :\\n\",final_hash2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W-GRAM DOKUMEN PERTAMA :\n",
      " [[793, 768, 757, 788], [768, 757, 788, 747], [757, 788, 747, 791], [788, 747, 791, 786], [747, 791, 786, 749], [791, 786, 749, 773], [786, 749, 773, 723], [749, 773, 723, 785], [773, 723, 785, 758], [723, 785, 758, 773], [785, 758, 773, 735], [758, 773, 735, 716], [773, 735, 716, 757], [735, 716, 757, 745], [716, 757, 745, 711], [757, 745, 711, 728], [745, 711, 728, 737], [711, 728, 737, 781], [728, 737, 781, 767], [737, 781, 767, 803], [781, 767, 803, 783], [767, 803, 783, 746], [803, 783, 746, 721], [783, 746, 721, 780], [746, 721, 780, 729], [721, 780, 729, 767], [780, 729, 767, 738], [729, 767, 738, 797], [767, 738, 797, 772], [738, 797, 772, 713]]\n",
      "\n",
      "\n",
      "W-GRAM DOKUMEN KEDUA :\n",
      " [[793, 768, 757, 788], [768, 757, 788, 747], [757, 788, 747, 791], [788, 747, 791, 786], [747, 791, 786, 749], [791, 786, 749, 773], [786, 749, 773, 733], [749, 773, 733, 807], [773, 733, 807, 803], [733, 807, 803, 783], [807, 803, 783, 746], [803, 783, 746, 721], [783, 746, 721, 780], [746, 721, 780, 729], [721, 780, 729, 767], [780, 729, 767, 738], [729, 767, 738, 797], [767, 738, 797, 772], [738, 797, 772, 713]]\n"
     ]
    }
   ],
   "source": [
    "def window (k_grams,final_hash):\n",
    "\ta = -1\n",
    "\tprewinnow = []\n",
    "\tfor i in range(len(k_grams)):\n",
    "\t\ta += 1\n",
    "\t\t#print (final_hash[0+a : w+a],min(final_hash[0+a : w+a]))\n",
    "\t\tprewinnow.append(final_hash[0+a : w+a])\n",
    "\t\tif w+a >= len(k_grams):\n",
    "\t\t\tbreak\n",
    "\treturn prewinnow\n",
    "\n",
    "windows1 = window(k_grams1,final_hash1)\n",
    "windows2 = window(k_grams2,final_hash2)\n",
    "print (\"W-GRAM DOKUMEN PERTAMA :\\n\",windows1)\n",
    "print ('\\n')\n",
    "print (\"W-GRAM DOKUMEN KEDUA :\\n\",windows2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINGERPRINT DOKUMEN PERTAMA :\n",
      " [757, 747, 749, 723, 735, 716, 711, 728, 737, 767, 746, 721, 729, 738, 713]\n",
      "\n",
      "\n",
      "FINGERPRINT DOKUMEN KEDUA :\n",
      " [757, 747, 749, 733, 746, 721, 729, 738, 713]\n"
     ]
    }
   ],
   "source": [
    "#pemilihan fingerprint\n",
    "def selected_hash (windows):\n",
    "\tmin_window = []\n",
    "\tfor i in range(len(windows)):\n",
    "\t\tmin_window.append(min(windows[i]))\n",
    "\treturn min_window\n",
    "\n",
    "min_window1 = selected_hash(windows1)\n",
    "min_window2 = selected_hash(windows2)\n",
    "min_window1 = list(dict.fromkeys(min_window1))\n",
    "min_window2 = list(dict.fromkeys(min_window2))\n",
    "print (\"FINGERPRINT DOKUMEN PERTAMA :\\n\",min_window1)\n",
    "print ('\\n')\n",
    "print (\"FINGERPRINT DOKUMEN KEDUA :\\n\",min_window2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tingkat Similatiras dengan Algoritma Winnowing adalah 50.00 %\n"
     ]
    }
   ],
   "source": [
    "jaccard_similarity = (len(set(min_window1).intersection(set(min_window2)))) / (len(set(min_window1).union(set(min_window2)))) * 100\n",
    "print ('Tingkat Similatiras dengan Algoritma Winnowing adalah','{:0.2f}'.format(jaccard_similarity),'%')\n",
    "\n",
    "\n",
    "#print ('\\n\\n')\n",
    "#print ((len(set(min_window1).intersection(set(min_window2)))),' / ',(len(set(min_window1).union(set(min_window2)))),' = ',(jaccard_similarity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah total karakter dari dokumen pertama adalah = 35\n",
      "jumlah total karakter dari dokumen kedua adalah = 24\n",
      "jumlah total karakter kedua dokumen adalah 59\n"
     ]
    }
   ],
   "source": [
    "# lanjut ke metode ratcliff/obershelp\n",
    "# sequence string matching  #menghitung banyaknya karakter\n",
    "jumlah_karakter1 = len(result1)\n",
    "jumlah_karakter2 = len(result2)\n",
    "total_karakter = jumlah_karakter1 + jumlah_karakter2\n",
    "print ('jumlah total karakter dari dokumen pertama adalah =',jumlah_karakter1)\n",
    "print ('jumlah total karakter dari dokumen kedua adalah =',jumlah_karakter2)\n",
    "print ('jumlah total karakter kedua dokumen adalah',total_karakter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SUBSEQUENCE :\n",
      " ['universitas', 'sumatera', 'utara']  =  24 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "same_word = []\n",
    "i = 0\n",
    "for i in filtering1 :\n",
    "    if i in filtering2  :\n",
    "        same_word.append(i)\n",
    "\n",
    "kata_sama = np.array(same_word, dtype=list) \n",
    "total_subsequence = \"\".join(kata_sama)\n",
    "print(\"TOTAL SUBSEQUENCE :\\n\",same_word,' = ',len(total_subsequence),'\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tingkat similatiras dengan algoritma Ratcliff/Obershelp adalah : 81.36 %\n"
     ]
    }
   ],
   "source": [
    "nilai_similarity = ((2*len(total_subsequence)) / (total_karakter))*100\n",
    "print(\"tingkat similatiras dengan algoritma Ratcliff/Obershelp adalah :\",'{:0.2f}'.format(nilai_similarity),'%')\n",
    "\n",
    "#print ('2 * ',(len(total_subsequence)),' / ',total_karakter, ' = ')\n",
    "#print ((2*len(total_subsequence)),' / ',total_karakter, ' = ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah k-gram yang terbentuk pada dokumen pertama adalah =  33\n",
      "jumlah k-gram yang terbentuk pada dokumen kedua adalah =  22\n",
      "\n",
      "berikut adalah hasil fingerprint pada dokumen pertama:\n",
      "[757, 747, 749, 723, 735, 716]\n",
      "[711, 728, 737, 767, 746, 721]\n",
      "[729, 738, 713]\n",
      "\n",
      "berikut adalah hasil fingerprint pada dokumen kedua:\n",
      "[757, 747, 749, 733, 746, 721]\n",
      "[729, 738, 713]\n",
      "\n",
      "tingkat similatiras dengan algoritma Winnowing adalah 50.0 %\n",
      "\n",
      "berikut adalah pencarian substring yang terdapat pada kedua dokumen =  24\n",
      "['universitas', 'sumatera', 'utara']\n",
      "\n",
      "tingkat similatiras dengan algoritma Ratcliff/Obershelp adalah 81.36 %\n"
     ]
    }
   ],
   "source": [
    "def rapi (winnow):\n",
    "    for q in range(0, len(winnow), 6):\n",
    "        print(winnow[q:q+6])\n",
    "\n",
    "print ('jumlah k-gram yang terbentuk pada dokumen pertama adalah = ',len(k_grams1))\n",
    "print ('jumlah k-gram yang terbentuk pada dokumen kedua adalah = ',len(k_grams2))\n",
    "print ('\\nberikut adalah hasil fingerprint pada dokumen pertama:')\n",
    "rapi(min_window1)\n",
    "print ('\\nberikut adalah hasil fingerprint pada dokumen kedua:')\n",
    "rapi(min_window2)\n",
    "print ('\\ntingkat similatiras dengan algoritma Winnowing adalah',jaccard_similarity,'%')\n",
    "print ('\\nberikut adalah pencarian substring yang terdapat pada kedua dokumen = ',len(total_subsequence) )\n",
    "rapi(same_word)\n",
    "print ('\\ntingkat similatiras dengan algoritma Ratcliff/Obershelp adalah','{:0.2f}'.format(nilai_similarity),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+---------------------+\n",
      "|     properties     |   dokumen pertama   |    dokumen kedua    |\n",
      "+--------------------+---------------------+---------------------+\n",
      "|       author       |       yura bee      |       yura bee      |\n",
      "|  last_modified_by  |       yura bee      |       yura bee      |\n",
      "| last_modified_time | 2022-08-02 05:09:00 | 2022-08-02 05:10:00 |\n",
      "|    created_time    | 2022-08-02 05:09:00 | 2022-08-02 05:09:00 |\n",
      "|     word_count     |          44         |          34         |\n",
      "|      revision      |          2          |          3          |\n",
      "|    last_printed    |         None        |         None        |\n",
      "+--------------------+---------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "prop1 = read_doc1.core_properties\n",
    "prop2 = read_doc2.core_properties\n",
    "\n",
    "# Tentukan nama kolom \n",
    "tabelproperties = PrettyTable([\"properties\", \"dokumen pertama\", \"dokumen kedua\"])\n",
    "\n",
    "# Tambahkan data baris\n",
    "tabelproperties.add_row([\"author\",              prop1.author,           prop2.author])\n",
    "tabelproperties.add_row([\"last_modified_by\",    prop1.last_modified_by, prop2.last_modified_by])\n",
    "tabelproperties.add_row([\"last_modified_time\",  prop1.modified,         prop2.modified])\n",
    "tabelproperties.add_row([\"created_time\",        prop1.created,         prop2.created])\n",
    "tabelproperties.add_row([\"word_count\",          len(document1),         len(document2)])\n",
    "tabelproperties.add_row([\"revision\",            prop1.revision,         prop2.revision])\n",
    "tabelproperties.add_row([\"last_printed\",        prop1.last_printed,     prop2.last_printed])\n",
    "print(tabelproperties)\n",
    "\n",
    "raw_document1.close()\n",
    "raw_document2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "665ea9d0b276128b2e88578b844e1e86537fe9d3f74feec69cc5b3ee07a22e96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
